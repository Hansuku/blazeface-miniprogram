{"version":3,"sources":["index.js","face.js","box.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;AELA,ADGA,ADGA;AELA,ADGA,ADGA;AELA,ADGA,ADGA;AELA,ADGA,ADGA;AELA,ADGA,ADGA;AELA,ADGA,ADGA;AELA,ADGA,ADGA;AELA,ADGA,ADGA;AELA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst tfconv = require(\"@tensorflow/tfjs-converter\");\nconst face_1 = require(\"./face\");\nconst BLAZEFACE_MODEL_URL = 'https://tfhub.dev/tensorflow/tfjs-model/blazeface/1/default/1';\nasync function load({ maxFaces = 10, inputWidth = 128, inputHeight = 128, iouThreshold = 0.3, scoreThreshold = 0.75 } = {}) {\n    const blazeface = await tfconv.loadGraphModel(BLAZEFACE_MODEL_URL, { fromTFHub: true });\n    const model = new face_1.BlazeFaceModel(blazeface, inputWidth, inputHeight, maxFaces, iouThreshold, scoreThreshold);\n    return model;\n}\nexports.load = load;\nvar face_2 = require(\"./face\");\nexports.BlazeFaceModel = face_2.BlazeFaceModel;\n//# sourceMappingURL=index.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst tf = require(\"@tensorflow/tfjs-core\");\nconst box_1 = require(\"./box\");\nconst ANCHORS_CONFIG = {\n    'strides': [8, 16],\n    'anchors': [2, 6]\n};\nconst NUM_LANDMARKS = 6;\nfunction generateAnchors(width, height, outputSpec) {\n    const anchors = [];\n    for (let i = 0; i < outputSpec.strides.length; i++) {\n        const stride = outputSpec.strides[i];\n        const gridRows = Math.floor((height + stride - 1) / stride);\n        const gridCols = Math.floor((width + stride - 1) / stride);\n        const anchorsNum = outputSpec.anchors[i];\n        for (let gridY = 0; gridY < gridRows; gridY++) {\n            const anchorY = stride * (gridY + 0.5);\n            for (let gridX = 0; gridX < gridCols; gridX++) {\n                const anchorX = stride * (gridX + 0.5);\n                for (let n = 0; n < anchorsNum; n++) {\n                    anchors.push([anchorX, anchorY]);\n                }\n            }\n        }\n    }\n    return anchors;\n}\nfunction decodeBounds(boxOutputs, anchors, inputSize) {\n    const boxStarts = tf.slice(boxOutputs, [0, 1], [-1, 2]);\n    const centers = tf.add(boxStarts, anchors);\n    const boxSizes = tf.slice(boxOutputs, [0, 3], [-1, 2]);\n    const boxSizesNormalized = tf.div(boxSizes, inputSize);\n    const centersNormalized = tf.div(centers, inputSize);\n    const halfBoxSize = tf.div(boxSizesNormalized, 2);\n    const starts = tf.sub(centersNormalized, halfBoxSize);\n    const ends = tf.add(centersNormalized, halfBoxSize);\n    const startNormalized = tf.mul(starts, inputSize);\n    const endNormalized = tf.mul(ends, inputSize);\n    const concatAxis = 1;\n    return tf.concat2d([startNormalized, endNormalized], concatAxis);\n}\nfunction getInputTensorDimensions(input) {\n    return input instanceof tf.Tensor ? [input.shape[0], input.shape[1]] :\n        [input.height, input.width];\n}\nfunction flipFaceHorizontal(face, imageWidth) {\n    let flippedTopLeft, flippedBottomRight, flippedLandmarks;\n    if (face.topLeft instanceof tf.Tensor &&\n        face.bottomRight instanceof tf.Tensor) {\n        const [topLeft, bottomRight] = tf.tidy(() => {\n            return [\n                tf.concat([\n                    tf.sub(imageWidth - 1, face.topLeft.slice(0, 1)),\n                    face.topLeft.slice(1, 1)\n                ]),\n                tf.concat([\n                    tf.sub(imageWidth - 1, face.bottomRight.slice(0, 1)),\n                    face.bottomRight.slice(1, 1)\n                ])\n            ];\n        });\n        flippedTopLeft = topLeft;\n        flippedBottomRight = bottomRight;\n        if (face.landmarks != null) {\n            flippedLandmarks = tf.tidy(() => {\n                const a = tf.sub(tf.tensor1d([imageWidth - 1, 0]), face.landmarks);\n                const b = tf.tensor1d([1, -1]);\n                const product = tf.mul(a, b);\n                return product;\n            });\n        }\n    }\n    else {\n        const [topLeftX, topLeftY] = face.topLeft;\n        const [bottomRightX, bottomRightY] = face.bottomRight;\n        flippedTopLeft = [imageWidth - 1 - topLeftX, topLeftY];\n        flippedBottomRight = [imageWidth - 1 - bottomRightX, bottomRightY];\n        if (face.landmarks != null) {\n            flippedLandmarks =\n                face.landmarks.map((coord) => ([\n                    imageWidth - 1 - coord[0],\n                    coord[1]\n                ]));\n        }\n    }\n    const flippedFace = {\n        topLeft: flippedTopLeft,\n        bottomRight: flippedBottomRight\n    };\n    if (flippedLandmarks != null) {\n        flippedFace.landmarks = flippedLandmarks;\n    }\n    if (face.probability != null) {\n        flippedFace.probability = face.probability instanceof tf.Tensor ?\n            face.probability.clone() :\n            face.probability;\n    }\n    return flippedFace;\n}\nfunction scaleBoxFromPrediction(face, scaleFactor) {\n    return tf.tidy(() => {\n        let box;\n        if (face.hasOwnProperty('box')) {\n            box = face.box;\n        }\n        else {\n            box = face;\n        }\n        return box_1.scaleBox(box, scaleFactor).startEndTensor.squeeze();\n    });\n}\nclass BlazeFaceModel {\n    constructor(model, width, height, maxFaces, iouThreshold, scoreThreshold) {\n        this.blazeFaceModel = model;\n        this.width = width;\n        this.height = height;\n        this.maxFaces = maxFaces;\n        this.anchorsData = generateAnchors(width, height, ANCHORS_CONFIG);\n        this.anchors = tf.tensor2d(this.anchorsData);\n        this.inputSizeData = [width, height];\n        this.inputSize = tf.tensor1d([width, height]);\n        this.iouThreshold = iouThreshold;\n        this.scoreThreshold = scoreThreshold;\n    }\n    async getBoundingBoxes(inputImage, returnTensors, annotateBoxes = true) {\n        const [detectedOutputs, boxes, scores] = tf.tidy(() => {\n            const resizedImage = inputImage.resizeBilinear([this.width, this.height]);\n            const normalizedImage = tf.mul(tf.sub(resizedImage.div(255), 0.5), 2);\n            const batchedPrediction = this.blazeFaceModel.predict(normalizedImage);\n            const prediction = batchedPrediction.squeeze();\n            const decodedBounds = decodeBounds(prediction, this.anchors, this.inputSize);\n            const logits = tf.slice(prediction, [0, 0], [-1, 1]);\n            const scores = tf.sigmoid(logits).squeeze();\n            return [prediction, decodedBounds, scores];\n        });\n        const savedConsoleWarnFn = console.warn;\n        console.warn = () => { };\n        const boxIndicesTensor = tf.image.nonMaxSuppression(boxes, scores, this.maxFaces, this.iouThreshold, this.scoreThreshold);\n        console.warn = savedConsoleWarnFn;\n        const boxIndices = await boxIndicesTensor.array();\n        boxIndicesTensor.dispose();\n        let boundingBoxes = boxIndices.map((boxIndex) => tf.slice(boxes, [boxIndex, 0], [1, -1]));\n        if (!returnTensors) {\n            boundingBoxes = await Promise.all(boundingBoxes.map(async (boundingBox) => {\n                const vals = await boundingBox.array();\n                boundingBox.dispose();\n                return vals;\n            }));\n        }\n        const originalHeight = inputImage.shape[1];\n        const originalWidth = inputImage.shape[2];\n        let scaleFactor;\n        if (returnTensors) {\n            scaleFactor = tf.div([originalWidth, originalHeight], this.inputSize);\n        }\n        else {\n            scaleFactor = [\n                originalWidth / this.inputSizeData[0],\n                originalHeight / this.inputSizeData[1]\n            ];\n        }\n        const annotatedBoxes = [];\n        for (let i = 0; i < boundingBoxes.length; i++) {\n            const boundingBox = boundingBoxes[i];\n            const annotatedBox = tf.tidy(() => {\n                const box = boundingBox instanceof tf.Tensor ?\n                    box_1.createBox(boundingBox) :\n                    box_1.createBox(tf.tensor2d(boundingBox));\n                if (!annotateBoxes) {\n                    return box;\n                }\n                const boxIndex = boxIndices[i];\n                let anchor;\n                if (returnTensors) {\n                    anchor = this.anchors.slice([boxIndex, 0], [1, 2]);\n                }\n                else {\n                    anchor = this.anchorsData[boxIndex];\n                }\n                const landmarks = tf.slice(detectedOutputs, [boxIndex, NUM_LANDMARKS - 1], [1, -1])\n                    .squeeze()\n                    .reshape([NUM_LANDMARKS, -1]);\n                const probability = tf.slice(scores, [boxIndex], [1]);\n                return { box, landmarks, probability, anchor };\n            });\n            annotatedBoxes.push(annotatedBox);\n        }\n        boxes.dispose();\n        scores.dispose();\n        detectedOutputs.dispose();\n        return {\n            boxes: annotatedBoxes,\n            scaleFactor\n        };\n    }\n    async estimateFaces(input, returnTensors = false, flipHorizontal = false, annotateBoxes = true) {\n        const [, width] = getInputTensorDimensions(input);\n        const image = tf.tidy(() => {\n            if (!(input instanceof tf.Tensor)) {\n                input = tf.browser.fromPixels(input);\n            }\n            return input.toFloat().expandDims(0);\n        });\n        const { boxes, scaleFactor } = await this.getBoundingBoxes(image, returnTensors, annotateBoxes);\n        image.dispose();\n        if (returnTensors) {\n            return boxes.map((face) => {\n                const scaledBox = scaleBoxFromPrediction(face, scaleFactor);\n                let normalizedFace = {\n                    topLeft: scaledBox.slice([0], [2]),\n                    bottomRight: scaledBox.slice([2], [2])\n                };\n                if (annotateBoxes) {\n                    const { landmarks, probability, anchor } = face;\n                    const normalizedLandmarks = landmarks.add(anchor).mul(scaleFactor);\n                    normalizedFace.landmarks = normalizedLandmarks;\n                    normalizedFace.probability = probability;\n                }\n                if (flipHorizontal) {\n                    normalizedFace = flipFaceHorizontal(normalizedFace, width);\n                }\n                return normalizedFace;\n            });\n        }\n        return Promise.all(boxes.map(async (face) => {\n            const scaledBox = scaleBoxFromPrediction(face, scaleFactor);\n            let normalizedFace;\n            if (!annotateBoxes) {\n                const boxData = await scaledBox.array();\n                normalizedFace = {\n                    topLeft: boxData.slice(0, 2),\n                    bottomRight: boxData.slice(2)\n                };\n            }\n            else {\n                const [landmarkData, boxData, probabilityData] = await Promise.all([face.landmarks, scaledBox, face.probability].map(async (d) => d.array()));\n                const anchor = face.anchor;\n                const [scaleFactorX, scaleFactorY] = scaleFactor;\n                const scaledLandmarks = landmarkData\n                    .map(landmark => ([\n                    (landmark[0] + anchor[0]) * scaleFactorX,\n                    (landmark[1] + anchor[1]) * scaleFactorY\n                ]));\n                normalizedFace = {\n                    topLeft: boxData.slice(0, 2),\n                    bottomRight: boxData.slice(2),\n                    landmarks: scaledLandmarks,\n                    probability: probabilityData\n                };\n                box_1.disposeBox(face.box);\n                face.landmarks.dispose();\n                face.probability.dispose();\n            }\n            scaledBox.dispose();\n            if (flipHorizontal) {\n                normalizedFace = flipFaceHorizontal(normalizedFace, width);\n            }\n            return normalizedFace;\n        }));\n    }\n}\nexports.BlazeFaceModel = BlazeFaceModel;\n//# sourceMappingURL=face.js.map","\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst tf = require(\"@tensorflow/tfjs-core\");\nexports.disposeBox = (box) => {\n    box.startEndTensor.dispose();\n    box.startPoint.dispose();\n    box.endPoint.dispose();\n};\nexports.createBox = (startEndTensor) => ({\n    startEndTensor,\n    startPoint: tf.slice(startEndTensor, [0, 0], [-1, 2]),\n    endPoint: tf.slice(startEndTensor, [0, 2], [-1, 2])\n});\nexports.scaleBox = (box, factors) => {\n    const starts = tf.mul(box.startPoint, factors);\n    const ends = tf.mul(box.endPoint, factors);\n    const newCoordinates = tf.concat2d([starts, ends], 1);\n    return exports.createBox(newCoordinates);\n};\n//# sourceMappingURL=box.js.map"]}